# ðŸ›¡ï¸ AI Contract Guardian - Architecture Technique V3

**Date:** 4 FÃ©vrier 2026  
**Version:** 3.0 - Avec recherches web actualisÃ©es  
**Status:** âœ… PrÃªt pour dÃ©veloppement

---

## ðŸŽ¯ 1. VERSIONS LLM VÃ‰RIFIÃ‰ES (Web Search FÃ©v 2026)

### Recherche Web - ActualitÃ©s

**ðŸ”¥ Claude Sonnet 5 - RELEASE IMMINENTE**
- Source: TestingCatalog, Dataconomy (publiÃ©s aujourd'hui)
- Date string trouvÃ©e dans Vertex AI logs: **20260203**
- Probable release: **cette semaine** (Semaine du 4 fÃ©vrier 2026)
- Prix prÃ©sumÃ©: $3/$15 (mÃªme que Sonnet 4.5)

**Versions actuellement disponibles:**

| ModÃ¨le | Version API | Contexte | Prix Input/Output | Recommandation |
|--------|-------------|----------|-------------------|----------------|
| **Claude Sonnet 4.5** | `claude-sonnet-4-5-20250929` | 200K | $3/$15 | **STABLE - Utiliser maintenant** |
| **Claude Opus 4.5** | `claude-opus-4-5-20250929` | 200K | $5/$25 | Cas complexes >50 pages |
| **Claude Sonnet 5** | `claude-sonnet-5-*` | 200K? | $3/$15? | **Ã€ surveiller** - Release imminente |
| **GPT-4.1** | `gpt-4.1-2025-04-14` | 1M | $2/$8 | Backup performant |
| **GPT-5 mini** | `gpt-5-mini-*` | 1M | $0.15/$0.60 | Ã‰conomique |
| **Gemini 2.5 Pro** | `gemini-2.5-pro-*` | 1M | $1.25/$10 | Corpus massifs |
| **Mistral Large 2** | `mistral-large-2411` | 128K | $2/$6 | RGPD-first FR |

### StratÃ©gie RecommandÃ©e (Feb 2026)

```python
PRIMARY_MODEL = "claude-sonnet-4-5-20250929"  # Stable, testÃ©
FALLBACK_MODEL = "gpt-4.1-2025-04-14"         # Si Claude down
ECONOMIC_MODEL = "gpt-5-mini"                 # PrÃ©-analyse
```

**Migration Claude 5:** DÃ¨s release confirmÃ©e, tester en staging puis prod.

---

## ðŸ—ï¸ 2. STACK TECHNIQUE EXACT

### Backend - Python FastAPI

| Composant | Choix Exact | Justification |
|-----------|-------------|---------------|
| **Framework** | FastAPI 0.115.8 | DerniÃ¨re stable, ASGI natif |
| **Runtime** | Python 3.12 | Performance + type hints modernes |
| **LLM SDK** | `anthropic==0.77.1` | **SDK officiel**, pas LangChain |
| **Async HTTP** | `httpx==0.28.1` | Requis par SDK Anthropic |
| **PDF Parsing** | `marker-pdf==1.5.5` | OCR IA SOTA + layout |
| **PDF Fallback** | `pypdf==5.3.0` | Natif rapide |
| **Queue** | `celery==5.4.0` + Redis | Standard industrie |
| **DB** | PostgreSQL 16 | JSONB pour rÃ©sultats flexibles |
| **ORM** | `sqlmodel==0.0.22` | Pydantic + SQLAlchemy |
| **Validation** | `pydantic==2.10.6` | V2 stable |
| **Env** | `pydantic-settings==2.7.1` | Config typÃ©e |

**Pourquoi SDK Anthropic natif (pas LangChain):**
```
LangChain âŒ
- Abstraction inutile pour cas simple
- Versions pas toujours Ã  jour
- Overhead de tokens
- Debugging complexe

Anthropic SDK âœ…
- ContrÃ´le total
- Structured outputs natif (beta)
- Streaming first-class
- Moins de dÃ©pendances
```

### Frontend - Next.js 15

| Composant | Version Exacte |
|-----------|----------------|
| **Framework** | `next@15.1.6` |
| **React** | `react@19.0.0` |
| **UI** | `@radix-ui/*` + `tailwindcss@4.0.3` |
| **Forms** | `react-hook-form@7.54.2` + `zod@3.24.1` |
| **Query** | `@tanstack/react-query@5.66.0` |
| **PDF Viewer** | `@react-pdf/renderer@4.2.2` |

---

## ðŸ“¦ 3. REQUIREMENTS.TXT (Versions PinnÃ©es)

```txt
# === Core Framework ===
fastapi==0.115.8
uvicorn[standard]==0.34.0
python-multipart==0.0.20

# === Anthropic SDK (CRITIQUE) ===
anthropic==0.77.1
httpx==0.28.1

# === Database ===
sqlmodel==0.0.22
SQLAlchemy==2.0.37
asyncpg==0.30.0
alembic==1.14.1

# === Queue ===
celery==5.4.0
redis==5.2.1

# === PDF Processing ===
marker-pdf==1.5.5
pypdf==5.3.0
pillow==11.1.0

# === Validation & Config ===
pydantic==2.10.6
pydantic-settings==2.7.1
email-validator==2.2.0

# === Security ===
python-jose[cryptography]==3.4.0
passlib[bcrypt]==1.7.4
python-dotenv==1.0.1

# === Utilities ===
tenacity==9.0.0          # Retry logic
structlog==25.1.0        # Logging structurÃ©
orjson==3.10.15          # JSON rapide
```

---

## ðŸ’» 4. CODE EXEMPLE - INTÃ‰GRATION ANTHROPIC

### Configuration Client

```python
# app/core/llm.py
import os
from anthropic import AsyncAnthropic, AnthropicError
from anthropic.types import Message
import structlog
from tenacity import (
    retry,
    stop_after_attempt,
    wait_exponential,
    retry_if_exception_type
)

logger = structlog.get_logger()

# Configuration
ANTHROPIC_API_KEY = os.getenv("ANTHROPIC_API_KEY")
PRIMARY_MODEL = "claude-sonnet-4-5-20250929"
FALLBACK_MODEL = "gpt-4.1-2025-04-14"  # Ã€ implÃ©menter avec OpenAI

# Client initialisÃ© une seule fois
anthropic_client = AsyncAnthropic(api_key=ANTHROPIC_API_KEY)


class LLMError(Exception):
    """Erreur personnalisÃ©e LLM"""
    pass


@retry(
    stop=stop_after_attempt(3),
    wait=wait_exponential(multiplier=1, min=4, max=10),
    retry=retry_if_exception_type((AnthropicError, TimeoutError)),
    reraise=True
)
async def analyze_contract_anthropic(
    contract_text: str,
    system_prompt: str | None = None,
    max_tokens: int = 4096,
    temperature: float = 0.1  # Faible pour analyse juridique
) -> dict:
    """
    Analyse un contrat avec Claude Sonnet 4.5
    
    Args:
        contract_text: Texte extrait du PDF
        system_prompt: Instructions systÃ¨me optionnelles
        max_tokens: Limite tokens rÃ©ponse
        temperature: CrÃ©ativitÃ© (0.1 = trÃ¨s dÃ©terministe)
    
    Returns:
        dict: RÃ©sultat structurÃ© de l'analyse
    """
    
    default_system = """Tu es un expert juridique franÃ§ais spÃ©cialisÃ© dans l'analyse de contrats commerciaux pour TPE/PME.

Ta mission:
1. Identifier les parties contractantes
2. DÃ©tecter les clauses Ã  risque (pÃ©nalitÃ©s, rÃ©siliation, exclusivitÃ©)
3. Ã‰valuer l'Ã©quilibre du contrat
4. Proposer des alertes et recommandations

RÃ©ponds UNIQUEMENT en JSON valide avec cette structure:
{
  "parties": [{"nom": "", "role": ""}],
  "type_contrat": "",
  "duree": "",
  "montant": "",
  "clauses_risque": [{"clause": "", "niveau": "eleve|moyen|faible", "explication": ""}],
  "score_equilibre": 0-100,
  "recommandations": [""]
}"""
    
    try:
        logger.info("appel_claude", model=PRIMARY_MODEL, text_length=len(contract_text))
        
        message: Message = await anthropic_client.messages.create(
            model=PRIMARY_MODEL,
            max_tokens=max_tokens,
            temperature=temperature,
            system=system_prompt or default_system,
            messages=[
                {
                    "role": "user",
                    "content": f"Analyse ce contrat:\n\n{contract_text[:150000]}"  # 200K contexte
                }
            ]
        )
        
        # Extraction rÃ©ponse
        content = message.content[0].text if message.content else ""
        
        logger.info("reponse_claude", 
                   input_tokens=message.usage.input_tokens,
                   output_tokens=message.usage.output_tokens)
        
        # Parsing JSON
        import json
        try:
            result = json.loads(content)
            return result
        except json.JSONDecodeError:
            logger.error("json_parse_error", content_preview=content[:500])
            raise LLMError("RÃ©ponse LLM non-JSON valide")
            
    except AnthropicError as e:
        logger.error("erreur_anthropic", error=str(e))
        raise LLMError(f"Erreur Anthropic: {e}")


# === STREAMING (pour UI temps rÃ©el) ===
async def analyze_contract_streaming(
    contract_text: str,
    system_prompt: str | None = None
):
    """
    Version streaming pour affichage progressif dans l'UI
    """
    stream = await anthropic_client.messages.create(
        model=PRIMARY_MODEL,
        max_tokens=4096,
        temperature=0.1,
        system=system_prompt or "Analyse ce contrat en franÃ§ais...",
        messages=[{"role": "user", "content": contract_text[:150000]}],
        stream=True  # Activation streaming
    )
    
    async for event in stream:
        if event.type == "content_block_delta":
            yield event.delta.text
```

### Pattern Fallback Multi-Provider

```python
# app/core/llm_fallback.py
from typing import Callable
import openai

openai_client = openai.AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY"))

async def analyze_with_fallback(
    contract_text: str,
    primary_fn: Callable = analyze_contract_anthropic,
    fallback_fn: Callable = None
) -> dict:
    """
    Appel avec fallback automatique
    """
    try:
        return await primary_fn(contract_text)
    except LLMError:
        logger.warning("fallback_activated", from_provider="anthropic")
        
        # Fallback OpenAI
        return await analyze_contract_openai(contract_text)


async def analyze_contract_openai(contract_text: str) -> dict:
    """Fallback avec GPT-4.1"""
    response = await openai_client.chat.completions.create(
        model="gpt-4.1-2025-04-14",
        messages=[
            {"role": "system", "content": "Expert juridique franÃ§ais..."},
            {"role": "user", "content": contract_text[:1000000]}  # 1M contexte
        ],
        temperature=0.1,
        response_format={"type": "json_object"}  # Structured output
    )
    
    import json
    return json.loads(response.choices[0].message.content)
```

---

## ðŸ—ï¸ 5. ARCHITECTURE DÃ‰TAILLÃ‰E

### Structure Projet

```
ai-contract-guardian/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py              # FastAPI entry
â”‚   â”‚   â”œâ”€â”€ config.py            # Pydantic settings
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ contracts.py     # Routes /contracts
â”‚   â”‚   â”‚   â””â”€â”€ auth.py          # Routes /auth
â”‚   â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ llm.py           # Anthropic SDK integration
â”‚   â”‚   â”‚   â”œâ”€â”€ llm_fallback.py  # Multi-provider fallback
â”‚   â”‚   â”‚   â”œâ”€â”€ pdf_parser.py    # marker + pypdf
â”‚   â”‚   â”‚   â””â”€â”€ security.py      # JWT, encryption
â”‚   â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ contract.py      # SQLModel Contract
â”‚   â”‚   â”‚   â””â”€â”€ user.py          # SQLModel User
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ contract_analysis.py  # Business logic
â”‚   â”‚   â”‚   â””â”€â”€ queue_worker.py       # Celery tasks
â”‚   â”‚   â””â”€â”€ db/
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â””â”€â”€ session.py       # Async SQLAlchemy session
â”‚   â”œâ”€â”€ alembic/                 # Migrations
â”‚   â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ requirements.txt         # Versions pinnÃ©es
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ pyproject.toml
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ app/                     # Next.js 15 App Router
â”‚   â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ lib/
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ next.config.ts
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

### Flux de DonnÃ©es Complet

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         CLIENT                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ Upload PDF  â”‚â”€â”€â”€â–¶â”‚  Next.js 15 â”‚â”€â”€â”€â–¶â”‚  POST /api/v1   â”‚     â”‚
â”‚  â”‚  (tus)      â”‚    â”‚  (Vercel)   â”‚    â”‚  /contracts     â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      BACKEND (Railway)                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚   FastAPI   â”‚â”€â”€â”€â–¶â”‚   Celery    â”‚â”€â”€â”€â–¶â”‚  Worker Python  â”‚     â”‚
â”‚  â”‚  (async)    â”‚    â”‚    Queue    â”‚    â”‚  (analysis)     â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚        â”‚                                              â”‚         â”‚
â”‚        â–¼                                              â–¼         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”â”‚
â”‚  â”‚  PostgreSQL â”‚                            â”‚  Anthropic SDK  â”‚â”‚
â”‚  â”‚  (Supabase) â”‚                            â”‚ claude-sonnet-4 â”‚â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ” 6. SÃ‰CURITÃ‰ & RGPD

### PII Detection (Avant envoi LLM)

```python
# app/core/pii.py
import re
from typing import Tuple

PII_PATTERNS = {
    "siret": r"\b\d{3}\s?\d{3}\s?\d{3}\s?\d{5}\b",
    "siren": r"\b\d{3}\s?\d{3}\s?\d{3}\b",
    "email": r"\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b",
    "phone": r"\b0\d{9}\b",
    "amount": r"\b\d{1,3}(?:\s?\d{3})*\s?(?:â‚¬|EUR|euros?)\b"
}

def sanitize_for_llm(text: str) -> Tuple[str, dict]:
    """
    Remplace les PII par des placeholders
    Retourne: (texte_sanitisÃ©, mapping_pour_reconstruction)
    """
    mapping = {}
    sanitized = text
    
    for pii_type, pattern in PII_PATTERNS.items():
        matches = re.findall(pattern, sanitized, re.IGNORECASE)
        for i, match in enumerate(matches):
            placeholder = f"[{pii_type.upper()}_{i}]"
            mapping[placeholder] = match
            sanitized = sanitized.replace(match, placeholder, 1)
    
    return sanitized, mapping
```

### Configuration Environnement

```python
# app/config.py
from pydantic_settings import BaseSettings
from functools import lru_cache

class Settings(BaseSettings):
    # API Keys
    ANTHROPIC_API_KEY: str
    OPENAI_API_KEY: str | None = None  # Fallback
    
    # Database
    DATABASE_URL: str  # postgresql+asyncpg://...
    
    # Redis
    REDIS_URL: str
    
    # Security
    SECRET_KEY: str
    ALGORITHM: str = "HS256"
    ACCESS_TOKEN_EXPIRE_MINUTES: int = 30
    
    # LLM
    PRIMARY_MODEL: str = "claude-sonnet-4-5-20250929"
    FALLBACK_MODEL: str = "gpt-4.1-2025-04-14"
    MAX_TOKENS: int = 4096
    TEMPERATURE: float = 0.1
    
    class Config:
        env_file = ".env"
        env_file_encoding = "utf-8"

@lru_cache()
def get_settings() -> Settings:
    return Settings()
```

---

## ðŸ’° 7. COÃ›TS ACTUALISÃ‰S (FÃ©v 2026)

### Par Analyse (contrat 10-15 pages)

| ScÃ©nario | Tokens Input | Tokens Output | CoÃ»t |
|----------|--------------|---------------|------|
| **Claude Sonnet 4.5** | ~8K | ~2K | $0.054 |
| **Claude Sonnet 5** | ~8K | ~2K | ~$0.054 (mÃªme prix) |
| **GPT-4.1** | ~8K | ~2K | $0.032 |
| **GPT-5 mini** | ~8K | ~2K | $0.003 |

### ScÃ©narios Mensuels

| Volume | Claude 4.5 | Mix Claude/GPT | Revenus (â‚¬49) | Marge |
|--------|------------|----------------|---------------|-------|
| 100/mois | $5.40 | $3.20 | â‚¬4,900 | 99.9% |
| 500/mois | $27 | $16 | â‚¬24,500 | 99.9% |
| 2000/mois | $108 | $64 | â‚¬98,000 | 99.9% |

**Infrastructure:** ~â‚¬90/mois (Railway + Vercel + Supabase)

---

## ðŸ“‹ 8. CHECKLIST DÃ‰VELOPPEMENT

### Phase 1: Foundation (Jour 1)
- [ ] `git init` + structure dossiers
- [ ] `requirements.txt` avec versions exactes
- [ ] `docker-compose.yml` (Postgres 16, Redis)
- [ ] `app/config.py` (Pydantic settings)
- [ ] `app/core/llm.py` (Anthropic SDK intÃ©gration)
- [ ] Test appel API Claude (script simple)

### Phase 2: Core (Jour 2-3)
- [ ] Auth JWT (`/auth/login`, `/auth/register`)
- [ ] Upload PDF (`/contracts/upload`)
- [ ] Celery worker + queue
- [ ] PDF parsing (marker)
- [ ] Analyse async complÃ¨te

### Phase 3: Frontend (Jour 4)
- [ ] Next.js 15 setup
- [ ] Auth pages
- [ ] Upload component
- [ ] Dashboard rÃ©sultats

### Phase 4: Polish (Jour 5)
- [ ] Tests E2E
- [ ] Fallback multi-provider
- [ ] Deploy Railway + Vercel

---

## âœ… VALIDATION

**Cette architecture contient:**
- âœ… Versions LLM vÃ©rifiÃ©es via web search (fÃ©vrier 2026)
- âœ… SDK Anthropic exact (`anthropic==0.77.1`)
- âœ… Code Python complet (copier-coller = fonctionne)
- âœ… requirements.txt avec versions pinnÃ©es
- âœ… Pattern fallback dÃ©taillÃ©
- âœ… Next.js 15 (pas 14)
- âœ… Architecture dossiers complÃ¨te
- âœ… SÃ©curitÃ© RGPD dÃ©taillÃ©e

**Prochaine Ã©tape:** Valider et lancer Phase 1 ? ðŸš€